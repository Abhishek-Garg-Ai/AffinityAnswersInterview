# -*- coding: utf-8 -*-
"""AffinityAnswersAssinment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rvRyG6ZeeZHLasMnEXnSwKDEZZiA_hG3

# Approach1
1.   Create a set of racial words that indicates racial slurs. e.g, ['xyz', 'abc', 'pqr', ...]
2.   Preprocess the text and remove redundant information.
2.   Tokenize each sentence(split it into list of words)
3.   Iterate through all the tokens present in given sentence and count the total number of racial words.
4.   Count the degree of profanity for sentence = Number of Racial Words / Total Number of words
"""

# Input all the racial words
racial_words=input().split()
# Read Racial Words from text file
# with open('racial_words.txt') as f:
#   racial_words=f.readlines()
racial_words

# Input all the racial words
sentences=input().split('.')
# Read Racial Words from text file
# with open('tweets.txt') as f:
#   sentences=f.readlines()
sentences

import string
def clean_text(text):
  '''
  Argument
  ---------------
  text : str | sentence which needs to be clean and tokenize

  Return 
  ---------------
  list of tokens or words
  '''
  # converting to lower case
  text = text.lower()
  # remove punctuation from text
  text = text.translate(str.maketrans('', '', string.punctuation))
  # Tokenization | split sentence into words
  tokens = text.split()
  # remove all tokens that are not alphabetic
  words = [word for word in tokens if word.isalpha()]
  return words

def get_profanity_score(tokens):
  '''
  Argument
  ---------------
  tokens : list | list all of tokens for a sentence

  Return 
  ---------------
  computed profanity score
  '''
  racial_counts=0
  for token in tokens:
    # If curr token is racial word than increase count by 1 
    if token in racial_words:
      racial_counts+=1
  return racial_counts/len(tokens)

# Iterating through each sentence
for sentence in sentences:
  # Tokenization
  tokens=clean_text(sentence)
  # Profanity Score
  score=get_profanity_score(tokens)



"""# Approach 2
1.   Instead of set, create dicttionary of racial words where each key-value pair represent racial slurs and word corresponding score for word. e.g, {'xyz':0.6, 'abc':0.4, 'pqr':0.8, ...}
2.   Preprocess the text and remove redundant information.
2.   Tokenize each sentence(split it into list of words)
3.   Iterate through all the tokens present in given sentence and sum the total score for all words.
4.   Count the degree of profanity for sentence = Sum of racial score/ Total Number of words
"""

# Input all the racial words
racial_dict={'xyz':0.6, 'abc':0.4, 'pqr':0.8}
racial_dict

# Input all the racial words
sentences=input().split('.')
# Read Racial Words from text file
# with open('tweets.txt') as f:
#   sentences=f.readlines()
sentences

def get_profanity_score(tokens):
  '''
  Argument
  ---------------
  tokens : list | list all of tokens for a sentence

  Return 
  ---------------
  computed profanity score
  '''
  racial_score=0
  for token in tokens:
    # If curr token is racial word than increase count by 1 
    if token in racial_dict.keys():
      racial_score+=racial_dict[token]
  return racial_score/len(tokens)

# Iterating through each sentence
for sentence in sentences:
  # Tokenization
  tokens=clean_text(sentence)
  # Profanity Score
  score=get_profanity_score(tokens)